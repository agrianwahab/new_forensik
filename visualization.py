"""
Visualization Module for Forensic Image Analysis System
Contains functions for creating comprehensive visualizations, plots, and visual reports
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from matplotlib.backends.backend_pdf import PdfPages
from PIL import Image
from datetime import datetime
from skimage.filters import sobel
import os
import io
import warnings

warnings.filterwarnings('ignore')

# ======================= Main Visualization Function =======================

def visualize_results_advanced(original_pil, analysis_results, output_filename="advanced_forensic_analysis.png"):
    """Advanced visualization with comprehensive results - MAIN FUNCTION"""
    print("üìä Creating advanced visualization...")
    
    # Create main figure with subplots
    fig = plt.figure(figsize=(28, 20))
    gs = fig.add_gridspec(4, 5, hspace=0.3, wspace=0.2)
    
    classification = analysis_results['classification']
    
    # Enhanced title
    fig.suptitle(
        f"Advanced Forensic Image Analysis Report\n"
        f"Analysis Complete - Processing Details Available\n"
        f"Features Analyzed: ELA, SIFT, Noise, JPEG, Frequency, Texture, Illumination",
        fontsize=16, fontweight='bold'
    )
    
    # Row 1: Basic Analysis
    # Original Image
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.imshow(original_pil)
    ax1.set_title("Original Image", fontsize=11)
    ax1.axis('off')
    
    # Multi-Quality ELA
    ax2 = fig.add_subplot(gs[0, 1])
    ela_display = ax2.imshow(analysis_results['ela_image'], cmap='hot')
    ax2.set_title(f"Multi-Quality ELA\n(Œº={analysis_results['ela_mean']:.1f}, œÉ={analysis_results['ela_std']:.1f})", fontsize=11)
    ax2.axis('off')
    plt.colorbar(ela_display, ax=ax2, fraction=0.046)
    
    # Feature Matches
    ax3 = fig.add_subplot(gs[0, 2])
    create_feature_match_visualization(ax3, original_pil, analysis_results)
    
    # Block Matches
    ax4 = fig.add_subplot(gs[0, 3])
    create_block_match_visualization(ax4, original_pil, analysis_results)
    
    # K-means Localization
    ax5 = fig.add_subplot(gs[0, 4])
    create_kmeans_clustering_visualization(ax5, original_pil, analysis_results)
    
    # Row 2: Advanced Analysis
    # Frequency Analysis
    ax6 = fig.add_subplot(gs[1, 0])
    create_frequency_visualization(ax6, analysis_results)
    
    # Texture Analysis
    ax7 = fig.add_subplot(gs[1, 1])
    create_texture_visualization(ax7, analysis_results)
    
    # Edge Analysis
    ax8 = fig.add_subplot(gs[1, 2])
    create_edge_visualization(ax8, original_pil, analysis_results)
    
    # Illumination Analysis
    ax9 = fig.add_subplot(gs[1, 3])
    create_illumination_visualization(ax9, original_pil, analysis_results)
    
    # JPEG Ghost
    ax10 = fig.add_subplot(gs[1, 4])
    ghost_display = ax10.imshow(analysis_results['jpeg_ghost'], cmap='hot')
    ax10.set_title(f"JPEG Ghost\n({analysis_results['jpeg_ghost_suspicious_ratio']:.1%} suspicious)", fontsize=11)
    ax10.axis('off')
    plt.colorbar(ghost_display, ax=ax10, fraction=0.046)
    
    # Row 3: Statistical Analysis
    # Statistical Plots
    ax11 = fig.add_subplot(gs[2, 0])
    create_statistical_visualization(ax11, analysis_results)
    
    # Noise Analysis
    ax12 = fig.add_subplot(gs[2, 1])
    ax12.imshow(analysis_results['noise_map'], cmap='gray')
    ax12.set_title(f"Noise Map\n(Inconsistency: {analysis_results['noise_analysis']['overall_inconsistency']:.3f})", fontsize=11)
    ax12.axis('off')
    
    # Quality Response Analysis
    ax13 = fig.add_subplot(gs[2, 2])
    create_quality_response_plot(ax13, analysis_results)
    
    # Combined Heatmap
    ax14 = fig.add_subplot(gs[2, 3])
    combined_heatmap = create_advanced_combined_heatmap(analysis_results, original_pil.size)
    ax14.imshow(combined_heatmap, cmap='hot', alpha=0.7)
    ax14.imshow(original_pil, alpha=0.3)
    ax14.set_title("Combined Suspicion Heatmap", fontsize=11)
    ax14.axis('off')
    
    # Technical Metrics
    ax15 = fig.add_subplot(gs[2, 4])
    create_technical_metrics_plot(ax15, analysis_results)
    
    # Row 4: Detailed Analysis Report
    ax16 = fig.add_subplot(gs[3, :])
    create_detailed_report(ax16, analysis_results)
    
    # Save with error handling
    try:
        plt.savefig(output_filename, dpi=300, bbox_inches='tight')
        print(f"üìä Advanced visualization saved as '{output_filename}'")
        plt.close()
        return output_filename
    except Exception as e:
        print(f"‚ùå Error saving visualization: {e}")
        plt.close()
        return None

# ======================= Individual Visualization Functions =======================

def create_feature_match_visualization(ax, original_pil, results):
    """Create feature match visualization"""
    img_matches = np.array(original_pil.convert('RGB'))
    
    if results['sift_keypoints'] and results['ransac_matches']:
        keypoints = results['sift_keypoints']
        matches = results['ransac_matches'][:20]  # Limit for clarity
        
        for match in matches:
            pt1 = tuple(map(int, keypoints[match.queryIdx].pt))
            pt2 = tuple(map(int, keypoints[match.trainIdx].pt))
            cv2.line(img_matches, pt1, pt2, (0, 255, 0), 2)
            cv2.circle(img_matches, pt1, 5, (255, 0, 0), -1)
            cv2.circle(img_matches, pt2, 5, (255, 0, 0), -1)
    
    ax.imshow(img_matches)
    ax.set_title(f"RANSAC Verified Matches\n({results['ransac_inliers']} inliers)", fontsize=11)
    ax.axis('off')

def create_block_match_visualization(ax, original_pil, results):
    """Create block match visualization"""
    img_blocks = np.array(original_pil.convert('RGB'))
    
    if results['block_matches']:
        for i, match in enumerate(results['block_matches'][:15]):  # Limit for clarity
            x1, y1 = match['block1']
            x2, y2 = match['block2']
            color = (255, 0, 0) if i % 2 == 0 else (0, 255, 0)
            cv2.rectangle(img_blocks, (x1, y1), (x1+16, y1+16), color, 2)
            cv2.rectangle(img_blocks, (x2, y2), (x2+16, y2+16), color, 2)
            cv2.line(img_blocks, (x1+8, y1+8), (x2+8, y2+8), (255, 255, 0), 1)
    
    ax.imshow(img_blocks)
    ax.set_title(f"Block Matches\n({len(results['block_matches'])} found)", fontsize=11)
    ax.axis('off')

def create_kmeans_clustering_visualization(ax, original_pil, analysis_results):
    """Create detailed K-means clustering visualization"""
    if 'localization_analysis' in analysis_results:
        loc_results = analysis_results['localization_analysis']
        kmeans_data = loc_results['kmeans_localization']
        
        # Check if ax is an Axes object or a SubplotSpec
        if hasattr(ax, 'get_subplotspec'):
            # ax is an Axes object, get its SubplotSpec
            subplot_spec = ax.get_subplotspec()
            # Clear the axes to use it for our grid
            ax.clear()
            ax.axis('off')
            # Create subplot untuk multiple visualizations
            from matplotlib.gridspec import GridSpecFromSubplotSpec
            gs = GridSpecFromSubplotSpec(2, 2, subplot_spec=subplot_spec, hspace=0.2, wspace=0.1)
        else:
            # ax is already a SubplotSpec
            from matplotlib.gridspec import GridSpecFromSubplotSpec
            gs = GridSpecFromSubplotSpec(2, 2, subplot_spec=ax, hspace=0.2, wspace=0.1)
        
        # 1. K-means Clusters (Top Left)
        ax1 = plt.subplot(gs[0, 0])
        cluster_map = kmeans_data['localization_map']
        n_clusters = len(np.unique(cluster_map))
        # Use different colormap untuk visualisasi cluster yang jelas
        cluster_display = ax1.imshow(cluster_map, cmap='tab10', alpha=0.8)
        ax1.imshow(original_pil, alpha=0.2)
        ax1.set_title(f"K-means Clusters (n={n_clusters})", fontsize=9)
        ax1.axis('off')
        # Add colorbar untuk cluster IDs
        cbar = plt.colorbar(cluster_display, ax=ax1, fraction=0.046)
        cbar.set_label('Cluster ID', fontsize=8)
        
        # 2. Tampering Cluster Highlight (Top Right)
        ax2 = plt.subplot(gs[0, 1])
        tampering_highlight = np.zeros_like(cluster_map)
        tampering_cluster_id = kmeans_data['tampering_cluster_id']
        tampering_highlight[cluster_map == tampering_cluster_id] = 1
        ax2.imshow(original_pil)
        ax2.imshow(tampering_highlight, cmap='Reds', alpha=0.6)
        ax2.set_title(f"Tampering Cluster (ID={tampering_cluster_id})", fontsize=9)
        ax2.axis('off')
        
        # 3. Cluster ELA Means Bar Chart (Bottom Left)
        ax3 = plt.subplot(gs[1, 0])
        cluster_means = kmeans_data['cluster_ela_means']
        cluster_ids = range(len(cluster_means))
        colors = ['red' if i == tampering_cluster_id else 'blue' for i in cluster_ids]
        bars = ax3.bar(cluster_ids, cluster_means, color=colors, alpha=0.7)
        ax3.set_xlabel('Cluster ID', fontsize=8)
        ax3.set_ylabel('Mean ELA Value', fontsize=8)
        ax3.set_title('Cluster ELA Analysis', fontsize=9)
        ax3.grid(True, alpha=0.3)
        # Add value labels on bars
        for bar, value in zip(bars, cluster_means):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.1f}', ha='center', va='bottom', fontsize=7)
        
        # 4. Combined Mask with Boundaries (Bottom Right)
        ax4 = plt.subplot(gs[1, 1])
        combined = loc_results['combined_tampering_mask']
        # Find cluster boundaries
        from scipy import ndimage
        boundaries = np.zeros_like(cluster_map)
        for i in range(n_clusters):
            mask = (cluster_map == i).astype(np.uint8)
            eroded = ndimage.binary_erosion(mask, iterations=1)
            boundaries += (mask - eroded)
        
        ax4.imshow(original_pil)
        ax4.imshow(combined, cmap='Reds', alpha=0.5)
        ax4.contour(boundaries, colors='yellow', linewidths=1, alpha=0.8)
        ax4.set_title(f"Final Detection ({loc_results['tampering_percentage']:.1f}%)", fontsize=9)
        ax4.axis('off')
        
        # Main title for the whole visualization
        ax.set_title("K-means Tampering Localization Analysis", fontsize=11, pad=10)
        ax.axis('off')
        
    else:
        # Fallback if no localization data
        ax.imshow(original_pil)
        ax.set_title("K-means Analysis Not Available", fontsize=11)
        ax.axis('off')

def create_localization_visualization(ax, original_pil, analysis_results):
    """Enhanced visualization hasil localization tampering"""
    if 'localization_analysis' in analysis_results:
        loc_results = analysis_results['localization_analysis']
        # Show combined tampering mask overlay
        img_overlay = np.array(original_pil.convert('RGB')).copy()
        mask = loc_results['combined_tampering_mask']
        
        if np.any(mask):
            # Create red overlay untuk tampering areas
            img_overlay[mask] = [255, 0, 0]  # Red color
            # Show overlay
            ax.imshow(img_overlay, alpha=0.8)
            ax.imshow(original_pil, alpha=0.2)
            ax.set_title(f"K-means Localization\n({loc_results['tampering_percentage']:.1f}% detected)", fontsize=11)
        else:
            # No tampering detected
            ax.imshow(original_pil)
            ax.set_title("K-means Localization\n(No tampering detected)", fontsize=11)
    else:
        # Fallback to ROI mask if localization not available
        if 'roi_mask' in analysis_results:
            ax.imshow(analysis_results['roi_mask'], cmap='gray')
            ax.set_title("ROI Mask", fontsize=11)
        else:
            ax.imshow(original_pil)
            ax.set_title("Localization Not Available", fontsize=11)
    
    ax.axis('off')

def create_frequency_visualization(ax, results):
    """Create frequency domain visualization"""
    freq_data = results['frequency_analysis']['dct_stats']
    categories = ['Low Freq', 'Mid Freq', 'High Freq']
    values = [freq_data['low_freq_energy'], freq_data['mid_freq_energy'], freq_data['high_freq_energy']]
    
    bars = ax.bar(categories, values, color=['blue', 'green', 'red'], alpha=0.7)
    ax.set_title(f"Frequency Domain\n(Inconsistency: {results['frequency_analysis']['frequency_inconsistency']:.2f})", fontsize=11)
    ax.set_ylabel('Energy')
    
    # Add value labels on bars
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{value:.0f}', ha='center', va='bottom', fontsize=9)

def create_texture_visualization(ax, results):
    """Create texture analysis visualization"""
    texture_data = results['texture_analysis']['texture_consistency']
    metrics = list(texture_data.keys())
    values = list(texture_data.values())
    
    bars = ax.barh(metrics, values, color='purple', alpha=0.7)
    ax.set_title(f"Texture Consistency\n(Overall: {results['texture_analysis']['overall_inconsistency']:.3f})", fontsize=11)
    ax.set_xlabel('Inconsistency Score')
    
    # Highlight high inconsistency
    for i, (bar, value) in enumerate(zip(bars, values)):
        if value > 0.3:
            bar.set_color('red')

def create_edge_visualization(ax, original_pil, results):
    """Create edge analysis visualization"""
    image_gray = np.array(original_pil.convert('L'))
    edges = sobel(image_gray)
    
    ax.imshow(edges, cmap='gray')
    ax.set_title(f"Edge Analysis\n(Inconsistency: {results['edge_analysis']['edge_inconsistency']:.3f})", fontsize=11)
    ax.axis('off')

def create_illumination_visualization(ax, original_pil, results):
    """Create illumination analysis visualization"""
    image_array = np.array(original_pil)
    lab = cv2.cvtColor(image_array, cv2.COLOR_RGB2LAB)
    illumination = lab[:, :, 0]
    
    ax.imshow(illumination, cmap='gray')
    ax.set_title(f"Illumination Map\n(Inconsistency: {results['illumination_analysis']['overall_illumination_inconsistency']:.3f})", fontsize=11)
    ax.axis('off')

def create_statistical_visualization(ax, results):
    """Create statistical analysis visualization"""
    stats = results['statistical_analysis']
    channels = ['R', 'G', 'B']
    entropies = [stats[f'{ch}_entropy'] for ch in channels]
    
    bars = ax.bar(channels, entropies, color=['red', 'green', 'blue'], alpha=0.7)
    ax.set_title(f"Channel Entropies\n(Overall: {stats['overall_entropy']:.3f})", fontsize=11)
    ax.set_ylabel('Entropy')
    
    for bar, value in zip(bars, entropies):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{value:.2f}', ha='center', va='bottom', fontsize=9)

def create_quality_response_plot(ax, results):
    """Create JPEG quality response plot"""
    quality_responses = results['jpeg_analysis']['quality_responses']
    qualities = [r['quality'] for r in quality_responses]
    responses = [r['response_mean'] for r in quality_responses]
    
    ax.plot(qualities, responses, 'b-o', linewidth=2, markersize=4)
    ax.set_title(f"JPEG Quality Response\n(Estimated Original: {results['jpeg_analysis']['estimated_original_quality']})", fontsize=11)
    ax.set_xlabel('Quality')
    ax.set_ylabel('Response')
    ax.grid(True, alpha=0.3)

def create_technical_metrics_plot(ax, results):
    """Create technical metrics plot"""
    metrics = ['ELA Mean', 'RANSAC', 'Blocks', 'Noise', 'JPEG']
    values = [
        results['ela_mean'],
        results['ransac_inliers'],
        len(results['block_matches']),
        results['noise_analysis']['overall_inconsistency'] * 100,
        results['jpeg_ghost_suspicious_ratio'] * 100
    ]
    
    colors = ['orange', 'green', 'blue', 'red', 'purple']
    bars = ax.bar(metrics, values, color=colors, alpha=0.8)
    ax.set_title("Technical Metrics Summary", fontsize=11)
    ax.set_ylabel('Score/Count')
    
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,
                f'{value:.1f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

def create_detailed_report(ax, analysis_results):
    """Create detailed text report"""
    ax.axis('off')
    
    classification = analysis_results['classification']
    metadata = analysis_results['metadata']
    
    report_text = f"""COMPREHENSIVE FORENSIC ANALYSIS REPORT

üîç TECHNICAL ANALYSIS SUMMARY:

üìä KEY METRICS:
‚Ä¢ ELA Analysis: Œº={analysis_results['ela_mean']:.2f}, œÉ={analysis_results['ela_std']:.2f}, Outliers={analysis_results['ela_regional_stats']['outlier_regions']}
‚Ä¢ Feature Matching: {analysis_results['sift_matches']} matches, {analysis_results['ransac_inliers']} verified
‚Ä¢ Block Matching: {len(analysis_results['block_matches'])} identical blocks detected
‚Ä¢ Noise Inconsistency: {analysis_results['noise_analysis']['overall_inconsistency']:.3f}
‚Ä¢ JPEG Anomalies: {analysis_results['jpeg_ghost_suspicious_ratio']:.1%} suspicious areas
‚Ä¢ Frequency Inconsistency: {analysis_results['frequency_analysis']['frequency_inconsistency']:.3f}
‚Ä¢ Texture Inconsistency: {analysis_results['texture_analysis']['overall_inconsistency']:.3f}
‚Ä¢ Edge Inconsistency: {analysis_results['edge_analysis']['edge_inconsistency']:.3f}
‚Ä¢ Illumination Inconsistency: {analysis_results['illumination_analysis']['overall_illumination_inconsistency']:.3f}

üîç METADATA ANALYSIS:
‚Ä¢ Authenticity Score: {metadata['Metadata_Authenticity_Score']}/100
‚Ä¢ Inconsistencies Found: {len(metadata['Metadata_Inconsistency'])}
‚Ä¢ File Size: {metadata.get('FileSize (bytes)', 'Unknown'):,} bytes

üìã TECHNICAL DETAILS:"""
    
    for detail in classification['details']:
        report_text += f"\n {detail}"
    
    report_text += f"""

üìä ANALYSIS METHODOLOGY:
‚Ä¢ 16-stage comprehensive analysis pipeline
‚Ä¢ Multi-quality ELA with cross-validation
‚Ä¢ Multi-detector feature analysis (SIFT/ORB/AKAZE)
‚Ä¢ Advanced statistical and frequency domain analysis
‚Ä¢ Machine learning classification with confidence estimation

üîß PROCESSING INFORMATION:
‚Ä¢ Total features analyzed: 25+ parameters
‚Ä¢ Analysis methods: Error Level Analysis, Feature Matching, Block Analysis
‚Ä¢ Noise Consistency, JPEG Analysis, Frequency Domain, Texture/Edge Analysis
‚Ä¢ Illumination Consistency, Statistical Analysis, Machine Learning Classification"""
    
    # Format and display text
    ax.text(0.02, 0.98, report_text, transform=ax.transAxes,
            fontsize=9, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))

def create_advanced_combined_heatmap(analysis_results, image_size):
    """Create advanced combined suspicion heatmap"""
    w, h = image_size
    heatmap = np.zeros((h, w))
    
    # ELA contribution (30%)
    ela_resized = cv2.resize(np.array(analysis_results['ela_image']), (w, h))
    heatmap += (ela_resized / 255.0) * 0.3
    
    # JPEG ghost contribution (25%)
    ghost_resized = cv2.resize(analysis_results['jpeg_ghost'], (w, h))
    heatmap += ghost_resized * 0.25
    
    # Feature points (20%)
    if analysis_results['sift_keypoints']:
        for kp in analysis_results['sift_keypoints'][:100]:  # Limit to prevent overcrowding
            x, y = int(kp.pt[0]), int(kp.pt[1])
            if 0 <= x < w and 0 <= y < h:
                cv2.circle(heatmap, (x, y), 15, 0.2, -1)
    
    # Block matches (25%)
    for match in analysis_results['block_matches'][:30]:
        x1, y1 = match['block1']
        x2, y2 = match['block2']
        cv2.rectangle(heatmap, (x1, y1), (x1+16, y1+16), 0.4, -1)
        cv2.rectangle(heatmap, (x2, y2), (x2+16, y2+16), 0.4, -1)
    
    # Normalize
    heatmap = np.clip(heatmap, 0, 1)
    return heatmap

def create_summary_report(ax, analysis_results):
    """Create summary report for PDF visualization"""
    ax.axis('off')
    
    classification = analysis_results['classification']
    
    summary_text = f"""FORENSIC ANALYSIS SUMMARY REPORT
{'='*50}

FINAL CLASSIFICATION: {classification['type']}
CONFIDENCE LEVEL: {classification['confidence']}

SCORING BREAKDOWN:
‚Ä¢ Copy-Move Score: {classification['copy_move_score']}/100
‚Ä¢ Splicing Score: {classification['splicing_score']}/100

KEY FINDINGS:"""
    
    for detail in classification['details'][:8]:  # Limit for space
        summary_text += f"\n‚Ä¢ {detail}"
    
    summary_text += f"""

TECHNICAL SUMMARY:
‚Ä¢ ELA Mean: {analysis_results['ela_mean']:.2f}
‚Ä¢ RANSAC Inliers: {analysis_results['ransac_inliers']}
‚Ä¢ Block Matches: {len(analysis_results['block_matches'])}
‚Ä¢ Noise Inconsistency: {analysis_results['noise_analysis']['overall_inconsistency']:.3f}
‚Ä¢ JPEG Anomalies: {analysis_results['jpeg_ghost_suspicious_ratio']:.1%}

ANALYSIS METHODOLOGY:
16-stage comprehensive pipeline with multi-algorithm detection,
cross-validation, and machine learning classification."""
    
    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,
            fontsize=11, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

# ======================= Standalone Export Functions =======================

def export_kmeans_visualization(original_pil, analysis_results, output_filename="kmeans_analysis.jpg"):
    """Export standalone K-means visualization"""
    if 'localization_analysis' not in analysis_results:
        print("‚ùå K-means analysis not available")
        return None
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('K-means Clustering Analysis for Tampering Detection', fontsize=16)
    
    loc_results = analysis_results['localization_analysis']
    kmeans_data = loc_results['kmeans_localization']
    
    # 1. Original Image
    axes[0, 0].imshow(original_pil)
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')
    
    # 2. K-means Clusters
    im1 = axes[0, 1].imshow(kmeans_data['localization_map'], cmap='viridis')
    axes[0, 1].set_title('K-means Clusters')
    axes[0, 1].axis('off')
    plt.colorbar(im1, ax=axes[0, 1])
    
    # 3. Tampering Mask
    im2 = axes[0, 2].imshow(kmeans_data['tampering_mask'], cmap='RdYlBu_r')
    axes[0, 2].set_title(f'Tampering Mask (Cluster {kmeans_data["tampering_cluster_id"]})')
    axes[0, 2].axis('off')
    
    # 4. ELA with Clusters Overlay
    axes[1, 0].imshow(analysis_results['ela_image'], cmap='hot')
    axes[1, 0].contour(kmeans_data['localization_map'], colors='cyan', alpha=0.5)
    axes[1, 0].set_title('ELA with Cluster Boundaries')
    axes[1, 0].axis('off')
    
    # 5. Combined Detection
    axes[1, 1].imshow(original_pil)
    axes[1, 1].imshow(loc_results['combined_tampering_mask'], cmap='Reds', alpha=0.5)
    axes[1, 1].set_title(f'Final Detection ({loc_results["tampering_percentage"]:.1f}%)')
    axes[1, 1].axis('off')
    
    # 6. Cluster Statistics
    ax_stats = axes[1, 2]
    cluster_means = kmeans_data['cluster_ela_means']
    x = range(len(cluster_means))
    colors = ['red' if i == kmeans_data['tampering_cluster_id'] else 'skyblue' for i in x]
    bars = ax_stats.bar(x, cluster_means, color=colors)
    ax_stats.set_xlabel('Cluster ID')
    ax_stats.set_ylabel('Mean ELA Value')
    ax_stats.set_title('Cluster ELA Statistics')
    ax_stats.grid(True, alpha=0.3)
    
    # Add annotations for tampering cluster
    for i, (bar, mean) in enumerate(zip(bars, cluster_means)):
        if i == kmeans_data['tampering_cluster_id']:
            ax_stats.annotate('Tampering', xy=(bar.get_x() + bar.get_width()/2, mean),
                            xytext=(0, 10), textcoords='offset points',
                            ha='center', fontsize=8, color='red',
                            arrowprops=dict(arrowstyle='->', color='red'))
    
    plt.tight_layout()
    
    # Save sebagai JPG dengan handling error
    try:
        # Method 1: Direct save as JPG
        plt.savefig(output_filename, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none', format='jpg')
        print(f"üìä K-means visualization saved as '{output_filename}'")
        plt.close()
        return output_filename
    except Exception as e:
        print(f"‚ö† JPG save failed: {e}, trying PNG conversion...")
        # Method 2: Save as PNG first, then convert
        try:
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            buf.seek(0)
            img = Image.open(buf)
            if img.mode == 'RGBA':
                img = img.convert('RGB')
            img.save(output_filename, 'JPEG', quality=95, optimize=True)
            print(f"üìä K-means visualization saved as '{output_filename}' (via PNG conversion)")
            plt.close()
            buf.close()
            return output_filename
        except Exception as e2:
            print(f"‚ùå K-means visualization export failed: {e2}")
            plt.close()
            return None

def export_visualization_png(original_pil, analysis_results, output_filename="forensic_analysis.png"):
    """Export visualization to PNG format with high quality"""
    print("üìä Creating PNG visualization...")
    
    # Use the main visualization function
    return visualize_results_advanced(original_pil, analysis_results, output_filename)

def export_visualization_pdf(original_pil, analysis_results, output_filename="forensic_analysis.pdf"):
    """Export visualization to PDF format"""
    print("üìä Creating PDF visualization...")
    
    with PdfPages(output_filename) as pdf:
        # Page 1: Main Analysis
        fig1 = plt.figure(figsize=(16, 12))
        gs1 = fig1.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        fig1.suptitle("Forensic Image Analysis - Main Results", fontsize=16, fontweight='bold')
        
        # Row 1: Core Analysis
        ax1 = fig1.add_subplot(gs1[0, 0])
        ax1.imshow(original_pil)
        ax1.set_title("Original Image", fontsize=12)
        ax1.axis('off')
        
        ax2 = fig1.add_subplot(gs1[0, 1])
        ela_display = ax2.imshow(analysis_results['ela_image'], cmap='hot')
        ax2.set_title(f"ELA (Œº={analysis_results['ela_mean']:.1f})", fontsize=12)
        ax2.axis('off')
        plt.colorbar(ela_display, ax=ax2, fraction=0.046)
        
        ax3 = fig1.add_subplot(gs1[0, 2])
        create_feature_match_visualization(ax3, original_pil, analysis_results)
        
        ax4 = fig1.add_subplot(gs1[0, 3])
        create_block_match_visualization(ax4, original_pil, analysis_results)
        
        # Row 2: Advanced Analysis
        ax5 = fig1.add_subplot(gs1[1, 0])
        create_frequency_visualization(ax5, analysis_results)
        
        ax6 = fig1.add_subplot(gs1[1, 1])
        create_texture_visualization(ax6, analysis_results)
        
        ax7 = fig1.add_subplot(gs1[1, 2])
        ghost_display = ax7.imshow(analysis_results['jpeg_ghost'], cmap='hot')
        ax7.set_title(f"JPEG Ghost", fontsize=12)
        ax7.axis('off')
        plt.colorbar(ghost_display, ax=ax7, fraction=0.046)
        
        ax8 = fig1.add_subplot(gs1[1, 3])
        create_technical_metrics_plot(ax8, analysis_results)
        
        # Row 3: Summary
        ax9 = fig1.add_subplot(gs1[2, :])
        create_summary_report(ax9, analysis_results)
        
        pdf.savefig(fig1, bbox_inches='tight')
        plt.close()
        
        # Page 2: Detailed Analysis
        fig2 = plt.figure(figsize=(16, 12))
        gs2 = fig2.add_gridspec(2, 3, hspace=0.3, wspace=0.3)
        fig2.suptitle("Forensic Image Analysis - Detailed Results", fontsize=16, fontweight='bold')
        
        # Detailed visualizations
        ax10 = fig2.add_subplot(gs2[0, 0])
        create_edge_visualization(ax10, original_pil, analysis_results)
        
        ax11 = fig2.add_subplot(gs2[0, 1])
        create_illumination_visualization(ax11, original_pil, analysis_results)
        
        ax12 = fig2.add_subplot(gs2[0, 2])
        create_statistical_visualization(ax12, analysis_results)
        
        ax13 = fig2.add_subplot(gs2[1, 0])
        create_quality_response_plot(ax13, analysis_results)
        
        ax14 = fig2.add_subplot(gs2[1, 1])
        ax14.imshow(analysis_results['noise_map'], cmap='gray')
        ax14.set_title(f"Noise Map", fontsize=12)
        ax14.axis('off')
        
        ax15 = fig2.add_subplot(gs2[1, 2])
        combined_heatmap = create_advanced_combined_heatmap(analysis_results, original_pil.size)
        ax15.imshow(combined_heatmap, cmap='hot', alpha=0.7)
        ax15.imshow(original_pil, alpha=0.3)
        ax15.set_title("Combined Suspicion Heatmap", fontsize=12)
        ax15.axis('off')
        
        pdf.savefig(fig2, bbox_inches='tight')
        plt.close()
    
    print(f"üìä PDF visualization saved as '{output_filename}'")
    return output_filename

# ======================= Comprehensive Grid Visualization =======================

def create_comprehensive_visualization_grid(fig, gs, original_pil, analysis_results):
    """Create comprehensive visualization grid for main visualization function"""
    
    # This function organizes all the individual visualization functions
    # into a coherent grid layout
    
    # Row 1: Basic Analysis
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.imshow(original_pil)
    ax1.set_title("Original Image", fontsize=11)
    ax1.axis('off')
    
    ax2 = fig.add_subplot(gs[0, 1])
    ela_display = ax2.imshow(analysis_results['ela_image'], cmap='hot')
    ax2.set_title(f"Multi-Quality ELA\n(Œº={analysis_results['ela_mean']:.1f}, œÉ={analysis_results['ela_std']:.1f})", fontsize=11)
    ax2.axis('off')
    plt.colorbar(ela_display, ax=ax2, fraction=0.046)
    
    ax3 = fig.add_subplot(gs[0, 2])
    create_feature_match_visualization(ax3, original_pil, analysis_results)
    
    ax4 = fig.add_subplot(gs[0, 3])
    create_block_match_visualization(ax4, original_pil, analysis_results)
    
    ax5 = fig.add_subplot(gs[0, 4])
    create_kmeans_clustering_visualization(ax5, original_pil, analysis_results)
    
    # Row 2: Advanced Analysis
    ax6 = fig.add_subplot(gs[1, 0])
    create_frequency_visualization(ax6, analysis_results)
    
    ax7 = fig.add_subplot(gs[1, 1])
    create_texture_visualization(ax7, analysis_results)
    
    ax8 = fig.add_subplot(gs[1, 2])
    create_edge_visualization(ax8, original_pil, analysis_results)
    
    ax9 = fig.add_subplot(gs[1, 3])
    create_illumination_visualization(ax9, original_pil, analysis_results)
    
    ax10 = fig.add_subplot(gs[1, 4])
    ghost_display = ax10.imshow(analysis_results['jpeg_ghost'], cmap='hot')
    ax10.set_title(f"JPEG Ghost\n({analysis_results['jpeg_ghost_suspicious_ratio']:.1%} suspicious)", fontsize=11)
    ax10.axis('off')
    plt.colorbar(ghost_display, ax=ax10, fraction=0.046)
    
    # Continue with remaining rows...
    # (Implementation continues as in the main visualization function)

# ======================= Utility Functions =======================

def save_visualization_with_fallback(fig, output_filename, dpi=300):
    """Save visualization with multiple fallback methods"""
    try:
        # Method 1: Direct save
        fig.savefig(output_filename, dpi=dpi, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        return True
    except Exception as e:
        print(f"‚ö† Direct save failed: {e}")
        
        try:
            # Method 2: Save to buffer first
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=dpi, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            buf.seek(0)
            
            # Convert and save
            img = Image.open(buf)
            if img.mode == 'RGBA':
                img = img.convert('RGB')
            
            # Determine format from filename
            if output_filename.lower().endswith('.jpg') or output_filename.lower().endswith('.jpeg'):
                img.save(output_filename, 'JPEG', quality=95, optimize=True)
            else:
                img.save(output_filename, 'PNG', optimize=True)
            
            buf.close()
            return True
        except Exception as e2:
            print(f"‚ùå Buffer save failed: {e2}")
            return False

def create_visualization_metadata(analysis_results):
    """Create metadata for visualization files"""
    metadata = {
        'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'analysis_type': 'Advanced Forensic Image Analysis',
        'version': 'v2.0',
        'filename': analysis_results['metadata'].get('Filename', 'Unknown'),
        'file_size': analysis_results['metadata'].get('FileSize (bytes)', 0),
        'classification': analysis_results['classification']['type'],
        'confidence': analysis_results['classification']['confidence'],
        'key_metrics': {
            'ela_mean': analysis_results['ela_mean'],
            'ransac_inliers': analysis_results['ransac_inliers'],
            'block_matches': len(analysis_results['block_matches']),
            'noise_inconsistency': analysis_results['noise_analysis']['overall_inconsistency']
        }
    }
    return metadata

def validate_visualization_input(original_pil, analysis_results):
    """Validate input parameters for visualization functions"""
    if not hasattr(original_pil, 'size'):
        raise ValueError("Invalid image input")
    
    required_keys = ['ela_image', 'classification', 'metadata', 'ela_mean', 'ela_std']
    for key in required_keys:
        if key not in analysis_results:
            raise ValueError(f"Missing required analysis result: {key}")
    
    return True

# ======================= Export Summary =======================

def create_visualization_summary():
    """Create summary of available visualization functions"""
    
    summary = """
VISUALIZATION MODULE SUMMARY
============================

MAIN FUNCTIONS:
‚Ä¢ visualize_results_advanced() - Comprehensive 4x5 grid visualization
‚Ä¢ export_visualization_png() - High-quality PNG export
‚Ä¢ export_visualization_pdf() - Multi-page PDF export
‚Ä¢ export_kmeans_visualization() - Standalone K-means analysis

INDIVIDUAL VISUALIZATIONS:
‚Ä¢ create_feature_match_visualization() - SIFT/ORB/AKAZE matches
‚Ä¢ create_block_match_visualization() - Block duplicate detection
‚Ä¢ create_kmeans_clustering_visualization() - Tampering localization
‚Ä¢ create_frequency_visualization() - DCT frequency analysis
‚Ä¢ create_texture_visualization() - GLCM/LBP texture analysis
‚Ä¢ create_edge_visualization() - Edge density analysis
‚Ä¢ create_illumination_visualization() - Illumination consistency
‚Ä¢ create_statistical_visualization() - Channel entropy analysis
‚Ä¢ create_quality_response_plot() - JPEG quality curves
‚Ä¢ create_technical_metrics_plot() - Summary metrics
‚Ä¢ create_advanced_combined_heatmap() - Suspicion overlay

UTILITY FUNCTIONS:
‚Ä¢ save_visualization_with_fallback() - Robust file saving
‚Ä¢ create_visualization_metadata() - Metadata generation
‚Ä¢ validate_visualization_input() - Input validation

OUTPUT FORMATS:
‚Ä¢ PNG: High-resolution raster images
‚Ä¢ PDF: Multi-page vector documents
‚Ä¢ JPG: Compressed visualizations

FEATURES:
‚Ä¢ Error handling and fallback methods
‚Ä¢ Adaptive layout based on data availability
‚Ä¢ Professional formatting and annotations
‚Ä¢ Cross-platform compatibility
‚Ä¢ Memory-efficient processing
"""
    
    return summary
